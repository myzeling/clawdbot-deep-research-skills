import asyncio
import argparse
import os
import sys
from gpt_researcher import GPTResearcher

# === ğŸ›¡ï¸ COST & CONFIGURATION GUARD ===
# å¼ºåˆ¶é…ç½®ä»¥ç¡®ä¿ä½¿ç”¨ä½æˆæœ¬æ¨¡å‹ï¼Œå¹¶ä¼˜åŒ–æœç´¢ç­–ç•¥

def configure_env():
    """Ensure the environment is set up for low-cost research."""
    
    # 1. è®¾ç½®æœç´¢å¼•æ“ (Tavily å¯¹ Agent æœ€å‹å¥½)
    os.environ["RETRIEVER"] = "tavily"
    
    # 2. å¼ºåˆ¶è®¾ç½® LLM æ¨¡å‹
    # ä¼˜å…ˆæ£€æµ‹ Gemini (Flash æ¨¡å‹æ€§ä»·æ¯”æœ€é«˜)ï¼Œå¦‚æœæ²¡é…ç½®åˆ™å›é€€
    if os.getenv("GEMINI_API_KEY"):
        print("âœ… Configured: Using Google Gemini (Low Cost Mode)")
        os.environ["FAST_LLM"] = "google_gemini"
        os.environ["SMART_LLM"] = "google_gemini" 
    elif os.getenv("OPENAI_API_KEY"):
        print("âš ï¸ Warning: GEMINI_API_KEY not found. Using OpenAI (Check your costs).")
        # å¦‚æœæ˜¯ OpenAIï¼Œå»ºè®®ç”¨æˆ·åœ¨ç¯å¢ƒå˜é‡é‡Œé…ç½®æ¨¡å‹ä¸º gpt-4o-mini
    else:
        print("âŒ Critical Error: No API Key (Gemini or OpenAI) found.")
        sys.exit(1)

async def main():
    parser = argparse.ArgumentParser(description="Deep Research Worker Agent")
    parser.add_argument("--query", type=str, required=True, help="The research objective")
    parser.add_argument("--filename", type=str, default="research_output.md", help="Output filename")
    parser.add_argument("--report_type", type=str, default="research_report", help="Type of report")
    
    args = parser.parse_args()

    print(f"\nğŸš€ STARTING WORKER: {args.query}")
    print(f"ğŸ“„ Output Target: {args.filename}")

    try:
        # åˆå§‹åŒ– Researcher
        researcher = GPTResearcher(query=args.query, report_type=args.report_type)
        
        # 1. æ‰§è¡Œæœç´¢ä¸ç ”ç©¶
        print("ğŸ” Searching, Scraping & Reading (Please wait)...")
        await researcher.conduct_research()
        
        # 2. æ’°å†™æŠ¥å‘Šæ­£æ–‡
        print("âœï¸ Synthesizing Report...")
        report_content = await researcher.write_report()
        
        # 3. å…³é”®æ­¥éª¤ï¼šæå–å¹¶è¿½åŠ æƒå¨æ•°æ®æºé“¾æ¥
        print("ğŸ”— Extracting Sources...")
        source_urls = researcher.get_source_urls()
        
        sources_section = "\n\n## ğŸ“š æƒå¨å‚è€ƒèµ„æ–™ / Verified Data Sources\n"
        sources_section += "> **Note to Agent:** When rewriting, you MUST verify data against these links.\n\n"
        for url in source_urls:
            sources_section += f"- {url}\n"
            
        final_output = report_content + sources_section
        
        # 4. ä¿å­˜æ–‡ä»¶
        with open(args.filename, "w", encoding="utf-8") as f:
            f.write(final_output)
            
        print(f"âœ… DONE. Report with citations saved to {args.filename}")
        print(f"ğŸ“Š Total Sources Found: {len(source_urls)}")

    except Exception as e:
        print(f"âŒ ERROR: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    configure_env()
    asyncio.run(main())
